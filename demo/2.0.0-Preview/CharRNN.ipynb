{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char-RNN\n",
    "\n",
    "In this tutorial, we will build a char-rnn model for natural language generation. The training text is tokenized as a sequence of characters. After training, the model is able to output the probability distribution over the alphabet, therefore \"predicting\" the next character. By iterating this process, one can generate text snippets.\n",
    "\n",
    "Char-RNN processes text sequences of arbitrary length, and the loss function makes use of ordinary Scala control-flow features during the training phase. Therefore it is an instance of dynamic neural network.\n",
    "\n",
    "This implementation of Char-RNN is inspired by Andrej Karpathy's execellent blog post [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [Python/numpy implementation](https://gist.github.com/karpathy/d4dee566867f8291f086)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                                        \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                                \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                                          \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                                 \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                         \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.PrintWriter\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.math\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcollection.immutable.IndexedSeq\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.ExecutionContext.Implicits.global\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.concurrent.Task\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.std.iterable._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.syntax.all._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.factory.Nd4j\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.api.ndarray.INDArray\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.ops.transforms.Transforms\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.api.ops.impl.indexaccum.IMax\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.DoubleLiterals\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.INDArrayLiterals\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.CumulativeDoubleLayers\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.DoubleTraining\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.CumulativeINDArrayLayers\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.INDArrayWeights\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.Operators\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.Logging\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.feature.Factory\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.nd4j:nd4j-native-platform:0.8.0`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-cumulativedoublelayers:2.0.0-RC5`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-doubletraining:2.0.0-RC5`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-cumulativeindarraylayers:2.0.0-RC5`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-indarrayweights:2.0.0-RC5`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-indarrayliterals:2.0.0-RC5`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-logging:2.0.0-RC5`\n",
    "\n",
    "import java.io.PrintWriter\n",
    "import scala.math\n",
    "import collection.immutable.IndexedSeq\n",
    "import scala.io.Source\n",
    "import scala.concurrent.ExecutionContext.Implicits.global\n",
    "import scalaz.concurrent.Task\n",
    "import scalaz.std.iterable._\n",
    "import scalaz.syntax.all._\n",
    "import org.nd4j.linalg.factory.Nd4j\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "import org.nd4j.linalg.ops.transforms.Transforms\n",
    "import org.nd4j.linalg.api.ops.impl.indexaccum.IMax\n",
    "import com.thoughtworks.deeplearning.plugins.DoubleLiterals\n",
    "import com.thoughtworks.deeplearning.plugins.INDArrayLiterals\n",
    "import com.thoughtworks.deeplearning.plugins.CumulativeDoubleLayers\n",
    "import com.thoughtworks.deeplearning.plugins.DoubleTraining\n",
    "import com.thoughtworks.deeplearning.plugins.CumulativeINDArrayLayers\n",
    "import com.thoughtworks.deeplearning.plugins.INDArrayWeights\n",
    "import com.thoughtworks.deeplearning.plugins.Operators\n",
    "import com.thoughtworks.deeplearning.plugins.Logging\n",
    "import com.thoughtworks.feature.Factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpus, setting up plugins & parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"DeepLearning.scala\"\u001b[39m\n",
       "\u001b[36mdataSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m18\u001b[39m\n",
       "\u001b[36mixToChar\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mChar\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m'e'\u001b[39m, \u001b[32m's'\u001b[39m, \u001b[32m'n'\u001b[39m, \u001b[32m'.'\u001b[39m, \u001b[32m'a'\u001b[39m, \u001b[32m'i'\u001b[39m, \u001b[32m'L'\u001b[39m, \u001b[32m'g'\u001b[39m, \u001b[32m'l'\u001b[39m, \u001b[32m'p'\u001b[39m, \u001b[32m'c'\u001b[39m, \u001b[32m'r'\u001b[39m, \u001b[32m'D'\u001b[39m)\n",
       "\u001b[36mcharToIx\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mChar\u001b[39m, \u001b[32mInt\u001b[39m] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m'e'\u001b[39m -> \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m's'\u001b[39m -> \u001b[32m1\u001b[39m,\n",
       "  \u001b[32m'n'\u001b[39m -> \u001b[32m2\u001b[39m,\n",
       "  \u001b[32m'.'\u001b[39m -> \u001b[32m3\u001b[39m,\n",
       "  \u001b[32m'a'\u001b[39m -> \u001b[32m4\u001b[39m,\n",
       "  \u001b[32m'i'\u001b[39m -> \u001b[32m5\u001b[39m,\n",
       "  \u001b[32m'L'\u001b[39m -> \u001b[32m6\u001b[39m,\n",
       "  \u001b[32m'g'\u001b[39m -> \u001b[32m7\u001b[39m,\n",
       "  \u001b[32m'l'\u001b[39m -> \u001b[32m8\u001b[39m,\n",
       "  \u001b[32m'p'\u001b[39m -> \u001b[32m9\u001b[39m,\n",
       "  \u001b[32m'c'\u001b[39m -> \u001b[32m10\u001b[39m,\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mvocabSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m13\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36moneOfK\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = \"DeepLearning.scala\"\n",
    "val dataSize = data.size\n",
    "\n",
    "val ixToChar = data.toSet.toArray\n",
    "val charToIx = (for (i <- ixToChar.indices) yield (ixToChar(i), i)).toMap\n",
    "val vocabSize = ixToChar.size\n",
    "\n",
    "def oneOfK(c: Char) = Nd4j.zeros(vocabSize, 1).putScalar(charToIx(c), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait\u001b[39m \u001b[36mLearningRate\u001b[39m\n",
       "defined \u001b[32mtrait\u001b[39m \u001b[36mAdagrad\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait LearningRate extends INDArrayWeights {\n",
    "    val learningRate: Double\n",
    "    \n",
    "    trait INDArrayOptimizerApi extends super.INDArrayOptimizerApi { this: INDArrayOptimizer =>\n",
    "      override def delta: INDArray = super.delta mul learningRate\n",
    "    }\n",
    "    override type INDArrayOptimizer <: INDArrayOptimizerApi with Optimizer\n",
    "  }\n",
    "\n",
    "trait Adagrad extends INDArrayWeights {\n",
    "    val eps: Double\n",
    "    \n",
    "    trait INDArrayWeightApi extends super.INDArrayWeightApi { this: INDArrayWeight =>\n",
    "      var cache: Option[INDArray] = None\n",
    "    }\n",
    "\n",
    "    override type INDArrayWeight <: INDArrayWeightApi with Weight\n",
    "\n",
    "    trait INDArrayOptimizerApi extends super.INDArrayOptimizerApi { this: INDArrayOptimizer =>\n",
    "      private lazy val deltaLazy: INDArray = {\n",
    "        import org.nd4s.Implicits._\n",
    "        import weight._\n",
    "        val delta0 = super.delta\n",
    "        cache = Some(cache.getOrElse(Nd4j.zeros(delta0.shape: _*)) + delta0 * delta0)\n",
    "        delta0 / (Transforms.sqrt(cache.get) + eps)\n",
    "      }\n",
    "      override def delta = deltaLazy\n",
    "    }\n",
    "    override type INDArrayOptimizer <: INDArrayOptimizerApi with Optimizer\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interp.load(\"\"\"\n",
    "  val hyperparameters = Factory[Adagrad with LearningRate with DoubleTraining with CumulativeDoubleLayers with CumulativeINDArrayLayers with Operators with INDArrayLiterals with DoubleLiterals with Logging].newInstance(learningRate = 0.1, eps=1e-8)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayWeight\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.DoubleLayer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayLayer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.implicits._\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.INDArrayWeight\n",
    "import hyperparameters.DoubleLayer\n",
    "import hyperparameters.INDArrayLayer\n",
    "import hyperparameters.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mhiddenSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m100\u001b[39m\n",
       "\u001b[36mseqLength\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m25\u001b[39m\n",
       "\u001b[36mwxh\u001b[39m: \u001b[32mObject\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m = $sess.cmd4Wrapper$Helper$Anonymous$macro$1$1$Anonymous$macro$34$1@45e200c1\n",
       "\u001b[36mwhh\u001b[39m: \u001b[32mObject\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m = $sess.cmd4Wrapper$Helper$Anonymous$macro$1$1$Anonymous$macro$34$1@79848e87\n",
       "\u001b[36mwhy\u001b[39m: \u001b[32mObject\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m = $sess.cmd4Wrapper$Helper$Anonymous$macro$1$1$Anonymous$macro$34$1@5bb4b0cb\n",
       "\u001b[36mbh\u001b[39m: \u001b[32mObject\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m = $sess.cmd4Wrapper$Helper$Anonymous$macro$1$1$Anonymous$macro$34$1@3073f908\n",
       "\u001b[36mby\u001b[39m: \u001b[32mObject\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m = $sess.cmd4Wrapper$Helper$Anonymous$macro$1$1$Anonymous$macro$34$1@65c203cf"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hiddenSize = 100 // 100\n",
    "val seqLength = 25\n",
    "\n",
    "val wxh = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(hiddenSize, vocabSize) * 0.01)\n",
    "}\n",
    "\n",
    "val whh = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(hiddenSize, hiddenSize) * 0.01)\n",
    "}\n",
    "\n",
    "val why = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(vocabSize, hiddenSize) * 0.01)\n",
    "}\n",
    "\n",
    "val bh = INDArrayWeight(Nd4j.zeros(hiddenSize, 1))\n",
    "val by = INDArrayWeight(Nd4j.zeros(vocabSize, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtanh\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tanh(x: INDArrayLayer): INDArrayLayer = {\n",
    "  val exp_x = hyperparameters.exp(x)\n",
    "  val exp_nx = hyperparameters.exp(-x)\n",
    "  (exp_x - exp_nx) / (exp_x + exp_nx)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcharRNN\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def charRNN(x: INDArray, y: INDArray, hprev: INDArrayLayer): (DoubleLayer, INDArrayLayer, INDArrayLayer) = {\n",
    "    val hnext = tanh(wxh.dot(x) + whh.dot(hprev) + bh)\n",
    "    val yraw = why.dot(hnext) + by\n",
    "    val yraw_exp = hyperparameters.exp(yraw)\n",
    "    val prob = yraw_exp / yraw_exp.sum\n",
    "    val loss = -hyperparameters.log((prob * y).sum)\n",
    "    (loss, prob, hnext)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbatches\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mIndexedSeq\u001b[39m[(\u001b[32mChar\u001b[39m, \u001b[32mChar\u001b[39m)]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    (\u001b[32m'D'\u001b[39m, \u001b[32m'e'\u001b[39m),\n",
       "    (\u001b[32m'e'\u001b[39m, \u001b[32m'e'\u001b[39m),\n",
       "    (\u001b[32m'e'\u001b[39m, \u001b[32m'p'\u001b[39m),\n",
       "    (\u001b[32m'p'\u001b[39m, \u001b[32m'L'\u001b[39m),\n",
       "    (\u001b[32m'L'\u001b[39m, \u001b[32m'e'\u001b[39m),\n",
       "    (\u001b[32m'e'\u001b[39m, \u001b[32m'a'\u001b[39m),\n",
       "    (\u001b[32m'a'\u001b[39m, \u001b[32m'r'\u001b[39m),\n",
       "    (\u001b[32m'r'\u001b[39m, \u001b[32m'n'\u001b[39m),\n",
       "    (\u001b[32m'n'\u001b[39m, \u001b[32m'i'\u001b[39m),\n",
       "    (\u001b[32m'i'\u001b[39m, \u001b[32m'n'\u001b[39m),\n",
       "\u001b[33m...\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mWithHiddenLayer\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mBatch\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mLosses\u001b[39m\n",
       "\u001b[36mh\u001b[39m: \u001b[32mPrintWriter\u001b[39m = java.io.PrintWriter@72408227\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msingleBatch\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36minitH\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msingleRound\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mallRounds\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val batches = data.zip(data.tail).grouped(seqLength).toVector\n",
    "\n",
    "type WithHiddenLayer[A] = (A, INDArrayLayer)\n",
    "type Batch = IndexedSeq[(Char, Char)]\n",
    "type Losses = Vector[Double]\n",
    "\n",
    "val h = new PrintWriter(\"/tmp/log.txt\")\n",
    "\n",
    "def singleBatch(batch: WithHiddenLayer[Batch]): WithHiddenLayer[DoubleLayer] = {\n",
    "  batch match {\n",
    "    case (batchseq, hprev) => batchseq.foldLeft((DoubleLayer(0.0.forward), hprev)) {\n",
    "      (bstate: WithHiddenLayer[DoubleLayer], xy: (Char, Char)) =>\n",
    "        (bstate, xy) match {\n",
    "          case ((tot, localhprev), (x, y)) => {\n",
    "            charRNN(oneOfK(x), oneOfK(y), localhprev) match {\n",
    "              case (localloss, _, localhnext) => {\n",
    "                (tot + localloss, localhnext)\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "def initH = INDArrayLayer(Nd4j.zeros(hiddenSize, 1).forward)\n",
    "\n",
    "def singleRound(initprevloss: Losses): Task[Losses] =\n",
    "  (batches.foldLeftM((initprevloss, initH)) {\n",
    "    (bstate: WithHiddenLayer[Losses], batch: Batch) =>\n",
    "      bstate match {\n",
    "        case (prevloss, hprev) => singleBatch(batch, hprev) match {\n",
    "          case (bloss, hnext) => bloss.train.map {\n",
    "            (blossval: Double) => {\n",
    "                val nloss = prevloss.last * 0.999 + blossval * 0.001\n",
    "                h.println(nloss)\n",
    "                h.flush()\n",
    "                (prevloss :+ prevloss.last * 0.999 + blossval * 0.001, hnext)\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "  }).map {\n",
    "    (fstate: WithHiddenLayer[Losses]) =>\n",
    "      fstate match {\n",
    "        case (floss, _) => floss\n",
    "      }\n",
    "  }\n",
    "\n",
    "def allRounds: Task[Losses] = (0 until 1024).foldLeftM(Vector(-math.log(1.0 / vocabSize) * seqLength)) {\n",
    "  (ploss: Losses, round: Int) => singleRound(ploss)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and using it to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jul 20, 2017 10:26:31 AM $sess.cmd8Wrapper$Helper hnext\n",
      "SEVERE: An exception is thrown in layer $sess.cmd4Wrapper$Helper$Anonymous$macro$1$1$Anonymous$macro$20$1@9a7486\n",
      "java.lang.ClassCastException: org.bytedeco.javacpp.indexer.IntRawIndexer cannot be cast to org.bytedeco.javacpp.indexer.UByteRawIndexer\n",
      "\tat org.nd4j.linalg.api.buffer.BaseDataBuffer.getInt(BaseDataBuffer.java:892)\n",
      "\tat org.nd4j.linalg.api.ndarray.BaseNDArray.isScalar(BaseNDArray.java:1720)\n",
      "\tat org.nd4j.linalg.api.ndarray.BaseNDArray.size(BaseNDArray.java:4215)\n",
      "\tat org.nd4j.linalg.api.shape.Shape.newShapeNoCopy(Shape.java:956)\n",
      "\tat org.nd4j.linalg.api.ndarray.BaseNDArray.reshape(BaseNDArray.java:3617)\n",
      "\tat org.nd4j.linalg.api.ndarray.BaseNDArray.reshape(BaseNDArray.java:3672)\n",
      "\tat com.thoughtworks.deeplearning.plugins.INDArrayLayers$Nd4jIssues1869Workaround.broadcastFix(INDArrayLayers.scala:71)\n",
      "\tat com.thoughtworks.deeplearning.plugins.INDArrayLayers$INDArrayLayer$$anonfun$binary$1$$anonfun$apply$23$$anonfun$com$thoughtworks$deeplearning$plugins$INDArrayLayers$INDArrayLayer$$anonfun$$anonfun$$backward$2$1$$anonfun$apply$24.apply(INDArrayLayers.scala:730)\n",
      "\tat com.thoughtworks.deeplearning.plugins.INDArrayLayers$INDArrayLayer$$anonfun$binary$1$$anonfun$apply$23$$anonfun$com$thoughtworks$deeplearning$plugins$INDArrayLayers$INDArrayLayer$$anonfun$$anonfun$$backward$2$1$$anonfun$apply$24.apply(INDArrayLayers.scala:729)\n",
      "\tat com.thoughtworks.tryt.covariant$TryTFunctor$$anonfun$map$1$$anonfun$apply$1$$anonfun$apply$2.apply(covariant.scala:94)\n",
      "\tat scala.util.Try$.apply(Try.scala:192)\n",
      "\tat com.thoughtworks.tryt.covariant$TryTFunctor$$anonfun$map$1$$anonfun$apply$1.apply(covariant.scala:94)\n",
      "\tat com.thoughtworks.tryt.covariant$TryTFunctor$$anonfun$map$1$$anonfun$apply$1.apply(covariant.scala:93)\n",
      "\tat scala.util.Success.flatMap(Try.scala:231)\n",
      "\tat com.thoughtworks.tryt.covariant$TryTFunctor$$anonfun$map$1.apply(covariant.scala:93)\n",
      "\tat com.thoughtworks.tryt.covariant$TryTFunctor$$anonfun$map$1.apply(covariant.scala:92)\n",
      "\tat scalaz.Monad$$anonfun$map$1$$anonfun$apply$2.apply(Monad.scala:14)\n",
      "\tat com.thoughtworks.raii.covariant$ResourceFactoryTPoint$$anonfun$point$1.apply(covariant.scala:267)\n",
      "\tat com.thoughtworks.raii.covariant$ResourceFactoryTPoint$$anonfun$point$1.apply(covariant.scala:267)\n",
      "\tat scalaz.concurrent.Future$$anonfun$delay$1.apply(Future.scala:402)\n",
      "\tat scalaz.concurrent.Future$$anonfun$delay$1.apply(Future.scala:402)\n",
      "\tat scalaz.concurrent.Future.step(Future.scala:119)\n",
      "\tat scalaz.concurrent.Future.unsafePerformListen(Future.scala:75)\n",
      "\tat scalaz.concurrent.Future$$anonfun$unsafePerformListen$1$$anonfun$apply$4.apply(Future.scala:79)\n",
      "\tat scalaz.concurrent.Future$$anonfun$unsafePerformListen$1$$anonfun$apply$4.apply(Future.scala:79)\n",
      "\tat scalaz.Free$$anonfun$map$1.apply(Free.scala:91)\n",
      "\tat scalaz.Free$$anonfun$map$1.apply(Free.scala:91)\n",
      "\tat scalaz.Free.resume(Free.scala:109)\n",
      "\tat scalaz.Free.go2$1(Free.scala:153)\n",
      "\tat scalaz.Free.go(Free.scala:157)\n",
      "\tat scalaz.Free.run(Free.scala:263)\n",
      "\tat scalaz.concurrent.Future$$anonfun$async$1$$anonfun$apply$14.apply(Future.scala:428)\n",
      "\tat scalaz.concurrent.Future$$anonfun$async$1$$anonfun$apply$14.apply(Future.scala:428)\n",
      "\tat com.thoughtworks.raii.asynchronous$Do$$anonfun$jump$1.com$thoughtworks$raii$asynchronous$Do$$anonfun$$run$body$1(asynchronous.scala:309)\n",
      "\tat com.thoughtworks.raii.asynchronous$Do$$anonfun$jump$1$$anonfun$4.run(asynchronous.scala:308)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector(64.12373393653841, 64.10321271971497, 64.15078270616212, 64.16563069302275, 64.15465896366872, 64.1187209161055, 64.07121542779883, 64.0169910551045, 63.958908847815316, 63.89806231032316, 63.83592879173743, 63.773466675775204, 63.71086203976928, 63.64818259602306, 63.585463626825266, 63.522726950443506, 63.45998742176682, 63.397255790203076, 63.33454016678661, 63.271846862216336, 63.20918090523481, 63.14654637635879, 63.08394663942101, 63.02138450588179, 62.958862346800174, 62.896382184793026, 62.83394575774844, 62.771554568774, 62.70920992891483, 62.64691298697919, 62.584664754102036, 62.52246612551141, 62.46031789538583, 62.39822077297658, 62.336175392570574, 62.27418232447379, 62.212242079973166, 62.150355122048964, 62.08852186812499, 62.02674269689071, 61.96501795250977, 61.903347946765514, 61.841732964351884, 61.780173263680254, 61.718669081155795, 61.65722063295011, 61.59582811595261, 61.53449170938422, 61.473211577935146, 61.411987872801255, 61.35082073084857, 61.289710276773654, 61.228656625761296, 61.167659881957356, 61.10672014082315, 61.04583748888192, 60.985012004629056, 60.924243760140435, 60.86353281926833, 60.80287924032374, 60.742283075389366, 60.68174437122761, 60.62126316953156, 60.560839507552686, 60.50047341746101, 60.44016492713826, 60.37991406117226, 60.31972083978422, 60.2595852798084, 60.19950739528691, 60.13948719744918, 60.079524693445094, 60.01961988755985, 59.959772783513486, 59.89998338103782, 59.8402516776895, 59.78057766939499, 59.72096134944529, 59.66140270968855, 59.60190173952894, 59.54245842652711, 59.483072758634755, 59.423744718596765, 59.36447429052362, 59.30526145614979, 59.2461061959431, 59.18700848932723, 59.1279683135515, 59.06898564616682, 59.01006046284955, 58.951192737114084, 58.89238244361347, 58.8336295543687, 58.77493404097868, 58.71629587505312, 58.65771502592951, 58.59919146229377, 58.540725152789854, 58.48231606481679, 58.423964165837106, 58.36566942190693, 58.30743179873811, 58.24925126127782, 58.19112777365469, 58.13306129996829, 58.07505180373518, 58.017099246216944, 57.959203590695196, 57.90136479932598, 57.84358283261966, 57.78585765147034, 57.72818921663152, 57.670577487380775, 57.61302242471627, 57.5555239867816, 57.49808213241366, 57.440696820070826, 57.38336800830108, 57.32609565461295, 57.26887971702569, 57.21172015233606, 57.154616917444095, 57.09756996922034, 57.04057926433993, 56.9836447582524, 56.92676640704834, 56.86994416680392, 56.81317799302722, 56.75646784055335, 56.699813664371305, 56.64321541885812, 56.58667305909082, 56.530186539469945, 56.47375581401485, 56.41738083763064, 56.36106156334052, 56.304797945002115, 56.24858993638416, 56.19243749064705, 56.13634056213047, 56.08029910276453, 56.02431306554014, 55.96838240343409, 55.912507069526804, 55.85668701652482, 55.80092219652091, 55.74521256267336, 55.689558066204064, 55.63395866036652, 55.57841429659061, 55.52292492768296, 55.467490504448904, 55.41211097936601, 55.356786304536236, 55.3015164313872, 55.24630131145642, 55.19114089602584, 55.13603513648572, 55.08098398505439, 55.02598739249817, 54.971045310346994, 54.91615768928295, 54.86132448087379, 54.806545636254825, 54.75182110667161, 54.69715084305806, 54.64253479585142, 54.58797291626104, 54.53346515536252, 54.47901146428134, 54.424611793229715, 54.37026609361288, 54.31597431585853, 54.26173641056713, 54.20755232844549, 54.153422020129646, 54.099345437202274, 54.0453225286008, 53.99135324588664, 53.937437539650396, 53.88357536029342, 53.82976665856381, 53.77601138471961, 53.72230948906896, 53.66866092256716, 53.615065635380766, 53.561523577962724, 53.508034701356124, 53.45459895539587, 53.40121629038116, 53.347886657502734, 53.294610006562166, 53.24138628806802, 53.18821545210031, 53.13509744944598, 53.08203223100071, 53.029019746931205, 52.976059947573034, 52.92315278307084, 52.87029820403964, 52.81749616126109, 52.764746604431, 52.7120494844301, 52.659404751887394, 52.60681235718396, 52.55427225063164, 52.50178438276779, 52.44934870394175, 52.396965164730744, 52.34463371570189, 52.292354307651166, 52.24012689082376, 52.18795141533834, 52.13582783273356, 52.08375609280576, 52.031736145757854, 51.97976794369931, 51.927851436092936, 51.87598657406784, 51.82417330820401, 51.772411589189026, 51.720701367462475, 51.66904259404947, 51.61743521882845, 51.56587919322417, 51.514374468231566, 51.46292099417281, 51.41151872267819, 51.3601676037525, 51.308867588467486, 51.25761862769912, 51.20642067201981, 51.15527367312431, 51.10417758180098, 51.05313234846538, 51.00213792484134, 50.95119426090325, 50.900301308294424, 50.84945901792602, 50.798667341655786, 50.74792623013273, 50.69723563399458, 50.64659550548676, 50.596005794986965, 50.54546645363785, 50.494977433173986, 50.44453868453416, 50.39415015954802, 50.34381180889659, 50.29352358468351, 50.24328543756776, 50.193097319751644, 50.142959181868946, 50.09287097615987, 50.042832653595106, 49.99284416597246, 49.942905464778626, 49.893016502085096, 49.843177229296465, 49.79338759744711, 49.743647559293755, 49.69395706542754, 49.6443160683418, 49.59472451986118, 49.545182371319946, 49.49568957523742, 49.446246083341244, 49.39685184717023, 49.34750681896785, 49.298210950848876, 49.24896419545018, 49.199766503903575, 49.15061782804599, 49.101518120480186, 49.05246733391903, 49.003465419862614, 48.95451233063917, 48.90560801868357, 48.856752436420194, 48.80794553607924, 48.75918726999857, 48.71047759074479, 48.661816450691234, 48.61320380237974, 48.56463959839787, 48.51612379090442, 48.46765633282066, 48.419237176757804, 48.37086627561377, 48.32254358143547, 48.274269047695135, 48.22604262689228, 48.1778642715759, 48.12973393505735, 48.08165156998046, 48.033617129631864, 47.985630566568936, 47.937691834113544, 47.88980088521527, 47.84195767298932, 47.794162150241334, 47.74641427054077, 47.69871398696541, 47.65106125287813, 47.60345602114969, 47.5558982458363, 47.50838787996264, 47.46092487677962, 47.41350918994286, 47.366140772916076, 47.318819578851965, 47.27154556190415, 47.224318675137624, 47.17713887297782, 47.130006108822826, 47.08292033611457, 47.035881508640955, 46.98888958023672, 46.941944505022335, 46.895046237102065, 46.848194729910205, 46.80138993782513, 46.75463181449231, 46.70792031450017, 46.66125539152658, 46.614637000132795, 46.56806509450622, 46.5215396285825, 46.475060556760106, 46.42862783342526, 46.38224141324635, 46.33590125004203, 46.28960729857351, 46.24335951340894, 46.197157849219714, 46.15100226030627, 46.10489270167093, 46.058829127583806, 46.01281149277943, 45.966839752336455, 45.92091386078084, 45.8750337728625, 45.82919944379664, 45.783410828064376, 45.7376678813295, 45.691970558342554, 45.646318813780184, 45.60071260320104, 45.55515188155221, 45.50963660406235, 45.464166726006376, 45.418742202345484, 45.37336298856231, 45.32802904018597, 45.28274031266961, 45.23749676127266, 45.1922983411783, 45.14714500881077, 45.102036718365845, 45.056973426357764, 45.01195508850649, 44.966981660396144, 44.92205309765694, 44.87716935572369, 44.83233039043445, 44.78753615802986, 44.74278661413569, 44.69808171490195, 44.653421415984795, 44.60880567386029, 44.56423444367393, 44.51970768228981, 44.475225345717966, 44.43078739001276, 44.38639377103368, 44.342044445162124, 44.297739369181656, 44.25347849908272, 44.2092617912584, 44.16508920208427, 44.120960687921716, 44.07687620541387, 44.0328357110075, 43.98883916119437, 43.94488651238914, 43.900977721527795, 43.85711274499287, 43.81329153974772, 43.7695140626202, 43.72578027018142, 43.68209011946495, 43.638443567486284, 43.594840570946836, 43.551281086830336, 43.50776507198326, 43.46429248341581, 43.420863278001164, 43.37747741277529, 43.334134845175434, 43.29083553256171, 43.247579432218785, 43.20436650075528, 43.16119669607879, 43.118069975421804, 43.07498629576078, 43.03194561495226, 42.98894789029571, 42.94599307913552, 42.90308113921643, 42.860212028145895, 42.81738570327422, 42.774602122652745, 42.73186124335859, 42.68916302328962, 42.646507420443456, 42.603894392144745, 42.56132389689491, 42.51879589234012, 42.47631033628977, 42.43386718665421, 42.3914664013272, 42.34910793884023, 42.30679175699105, 42.26451781337998, 42.22228606702431, 42.18009647572738, 42.1379489977533, 42.09584359116771, 42.05378021437897, 42.01175882583551, 41.969779383728735, 41.92784184671028, 41.88594617281562, 41.844092321197756, 41.80228024997599, 41.76050991760959, 41.718781283016426, 41.67709430450031, 41.63544894070358, 41.593845150669836, 41.552282893483145, 41.51076212701365, 41.4692828109662, 41.427844904189335, 41.38644836497537, 41.34509315225668, 41.303779225363705, 41.262506543429545, 41.221275064971564, 41.18008474974163, 41.138935556578204, 41.0978274449556, 41.05676037415177, 41.01573430264879, 40.97474919070234, 40.933804996815624, 40.8929016808476, 40.85203920215989, 40.81121752009513, 40.770436594274656, 40.729696384421736, 40.68899684976009, 40.64833794991323, 40.60771964448701, 40.56714189312647, 40.52660465557636, 40.48610789221841, 40.44565156186323, 40.40523562515241, 40.36486004133523, 40.32452477071537, 40.28422977333994, 40.243975008875715, 40.20376043774725, 40.163586019820116, 40.123451715301265, 40.083357484137274, 40.04330328667336, 40.0032890829"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9524, 39.96331483370778, 39.92338049873641, 39.88348603822809, 39.8436314124871, 39.80381658269409, 39.76404150833733, 39.72430615055883, 39.68461046999937, 39.64495442716073, 39.60533798228743, 39.56576109661742, 39.526223730174074, 39.486725843737204, 39.44726739860309, 39.4078483547942, 39.368468673804934, 39.329128316152946, 39.28982724239669, 39.25056541384889, 39.21134279192267, 39.17215933705309, 39.133015010431286, 39.09390977281007, 39.05484358581811, 39.015816410703245, 38.97682820851332, 38.937878940336255, 38.898968567595546, 38.860097051755595, 38.82126435366122, 38.78247043539027, 38.74371525750648, 38.70499878204641, 38.66632097018787, 38.62768178398482, 38.58908118439326, 38.550519133424785, 38.511995592948495, 38.47351052421644, 38.43506388875598, 38.39665564902977, 38.35828576670249, 38.319954203238304, 38.28166092031921, 38.24340588097745, 38.20518904595495, 38.167010377525685, 38.12886983764262, 38.09076738877457, 38.052702992711446, 38.014676611878116, 37.976688208320404, 37.9387377443591, 37.90082518205455, 37.862950483565385, 37.82511361108845, 37.787314527215344, 37.74955319439688, 37.71182957530046, 37.67414363203276, 37.63649532697773, 37.598884623095266, 37.5613114830829, 37.52377586919786, 37.486277743794695, 37.44881706998209, 37.411393810488825, 37.37400792784008, 37.33665938519696, 37.2993481449808, 37.26207417042714, 37.22483742433019, 37.18763786910319, 37.15047546845156, 37.113350184802435, 37.07626198115872, 37.03921082121753, 37.002196668591495, 36.96521948501974, 36.92827923448894, 36.89137587964848, 36.854509384617444, 36.81767971211816, 36.780886825269334, 36.744130688359704, 36.707411263923305, 36.67072851572612, 36.63408240709145, 36.59747290167842, 36.56089996318217, 36.52436355503669, 36.48786364053283, 36.45140018401268, 36.41497314901831, 36.37858249894949, 36.34222819772037, 36.30591020916084, 36.26962849689853, 36.23338302501619, 36.19717375739358, 36.1610006580645, 36.12486369098089, 36.08876282006955, 36.0526980092355, 36.01666922277628, 35.98067642442902, 35.94471957868372, 35.908798649946434, 35.8729136023, 35.837064399982616, 35.80125100703028, 35.76547338781274, 35.72973150661535, 35.69402532817914, 35.65835481692021, 35.62271993735142, 35.587120653720895, 35.55155693079134, 35.51602873324141, 35.4805360252475, 35.445078771080716, 35.40965693600389, 35.374270485255266, 35.33891938279377, 35.303603593928635, 35.26832308322594, 35.23307781582638, 35.197867755591034, 35.16269286820833, 35.12755311910287, 35.09244847259864, 35.05737889377279, 35.022344347677006, 34.987344799338366, 34.9523802144165, 34.91745055770869, 34.88255579440649, 34.84769588955701, 34.812870808719765, 34.77808051730948, 34.743324980238704, 34.70860416305181, 34.67391803156617, 34.639266550619034, 34.60464968537999, 34.57006740224938, 34.53551966634582, 34.501006443182995, 34.46652769818766, 34.432083397359875, 34.39767350595688, 34.36329799046472, 34.32895681573176, 34.29464994795507, 34.26037735294702, 34.226138996195814, 34.19193484376171, 34.15776486221718, 34.12362901679443, 34.089527273774735, 34.055459598758056, 34.02142595791445, 33.98742631727022, 33.95346064360131, 33.91952890222457, 33.88563106016275, 33.851767083098814, 33.81793693692898, 33.784140588539614, 33.75037800371393, 33.71664914976365, 33.68295399188387, 33.64929249727335, 33.61566463137431, 33.58207036145278, 33.5485096538541, 33.51498247525403, 33.481488792243354, 33.44802857126714, 33.414601779041945, 33.38120838243777, 33.34784834746267, 33.31452164147162, 33.281228230955996, 33.24796808315777, 33.21474116433698, 33.18154744150333, 33.14838688152082, 33.115259451644725, 33.08216511880446, 33.049103850082055, 33.01607561259281, 32.98308037294737, 32.950118098327195, 32.91718875570773, 32.88429231275376, 32.85142873632677, 32.818597993441195, 32.78580005126395, 32.753034877650634, 32.72030243971358, 32.687602705015614, 32.654935640794115, 32.622301214557226, 32.589699393190074, 32.55713014468433, 32.52459343640804, 32.492089236059456, 32.45961751113087, 32.4271782292066, 32.394771358082295, 32.36239686528839, 32.3300547182669, 32.29774488556772, 32.26546733392125, 32.23322203152465, 32.20100894648612, 32.16882804635035, 32.13667929940965, 32.10456267291427, 32.07247813545997, 32.04042565489802, 32.00840519941053, 31.976416736852944, 31.944460235590718, 31.912535663244434, 31.88064298812465, 31.848782178453252, 31.816953202305804, 31.785156028385032, 31.75339062471045, 31.721656959630895, 31.689955000572468, 31.65828471732112, 31.626646077664343, 31.595039050078203, 31.56346360289065, 31.53191970511792, 31.500407324793475, 31.468926430459355, 31.437476990450794, 31.406058973790643, 31.37467234893649, 31.3433170844961, 31.311993149706815, 31.28070051294035, 31.249439143018364, 31.218209008852575, 31.187010079267463, 31.155842322938664, 31.124705709290474, 31.093600207239366, 31.062525785375875, 31.031482412440518, 31.00047005744436, 30.969488689489033, 30.938538278004977, 30.907618792095622, 30.876730200716278, 30.845872473270706, 30.815045578716212, 30.784249485980915, 30.75348416426343, 30.722749583985856, 30.692045713810703, 30.661372522788827, 30.630729980778536, 30.60011805677262, 30.569536720750172, 30.53898594170515, 30.508465689438896, 30.47797593342502, 30.447516643286193, 30.417087788138925, 30.3866893384441, 30.35632126302007, 30.32598353208907, 30.29567611554598, 30.26539898236027, 30.235152102845056, 30.20493544674708, 30.174748983962196, 30.14459268441656, 30.114466517887088, 30.084370454061855, 30.054304463256152, 30.024268515456818, 29.99426258026275, 29.96428662819887, 29.934340629162143, 29.90442455337862, 29.87453837080637, 29.84468205179038, 29.814855566229053, 29.785058884885046, 29.755291977775496, 29.725554814768383, 29.69584736665632, 29.666169603605493, 29.6365214957518, 29.606903014215916, 29.577314129072988, 29.547754809951165, 29.51822502865721, 29.48872475493659, 29.459253959342007, 29.429812612872333, 29.400400685780696, 29.371018148886364, 29.341664972619906, 29.31234112815812, 29.28304658604976, 29.25378131669408, 29.224545290818536, 29.195338479656865, 29.16616085387537, 29.137012384348363, 29.107893042038693, 29.078802798296984, 29.049741622950194, 29.020709487825414, 28.991706363762905, 28.962732221990635, 28.933787033287754, 28.904870768581606, 28.8759833995453, 28.84712489692471, 28.818295232271282, 28.789494376508365, 28.76072230076798, 28.731978976448673, 28.703264375216865, 28.67457846763377, 28.64592122584084, 28.617292621172574, 28.588692624096883, 28.560121207020277, 28.531578341064748, 28.503063997500046, 28.474578148460317, 28.44612076473529, 28.417691818336802, 28.389291281066065, 28.36091912439531, 28.332575320002817, 28.304259839596675, 28.275972654972026, 28.24771373759467, 28.219483059256888, 28.191280592136998, 28.163106307666244, 28.134960177721897, 28.106842174208992, 28.078752269538167, 28.050690435371873, 28.022656643759014, 27.99465086671677, 27.96667307581271, 27.938723243538398, 27.910801341696477, 27.882907343251688, 27.855041219166818, 27.827202942343302, 27.79939248505364, 27.771609819179375, 27.743854916929408, 27.716127750599806, 27.68842829287264, 27.66075651544233, 27.63311239140472, 27.605495893225406, 27.57790699250281, 27.550345661997774, 27.522811873961057, 27.495305601327697, 27.467826816343404, 27.440375491521074, 27.41295159999671, 27.385555113919693, 27.358186006063733, 27.330844248811445, 27.303529815170528, 27.276242677817706, 27.248982809635454, 27.221750183116264, 27.19454477107798, 27.167366546425345, 27.140215481732454, 27.1130915503766, 27.085994725164618, 27.058924978572858, 27.031882284059844, 27.00486661445394, 26.9778779426112, 26.950916241474005, 26.92398148496673, 26.897073645070808, 26.870192695466443, 26.84333860962123, 26.816511360134765, 26.789710920468707, 26.7629372641713, 26.73619036374352, 26.709470193085725, 26.682776725289045, 26.656109933889134, 26.629469792090582, 26.602856273184344, 26.57626935042812, 26.5497089978819, 26.52317518843891, 26.4966678958539, 26.470187093491205, 26.443732755039072, 26.417304853914683, 26.390903363442458, 26.364528257867676, 26.338179510447556, 26.31185709518181, 26.285560985559407, 26.259291155513434, 26.23304757852565, 26.206830228462692, 26.1806390789181, 26.15447410416919, 26.128335277981122, 26.10222257414597, 26.076135966601317, 26.050075429310112, 26.024040936381457, 25.998032461531864, 25.972049979042247, 25.94609346250241, 25.92016288636415, 25.894258224388626, 25.86837945101957, 25.842526540249306, 25.81669946639431, 25.79089820367722, 25.765122726107922, 25.73937300808038, 25.71364902389473, 25.68795074787697, 25.662278153782015, 25.636631216822916, 25.611009911103615, 25.585414210933482, 25.559844090646976, 25.534299524366254, 25.50878048707439, 25.48328695318248, 25.457818897545547, 25.43237629408824, 25.406959118253887, 25.381567343540706, 25.35620094532324, 25.330859897986237, 25.305544176178895, 25.280253754874014, 25.254988608532727, 25.22974871193956, 25.2045340401434, 25.179344567740127, 25.15418026953051, 25.129041120399922, 25.103927095378367, 25.078838169461037, 25.053774316893026, 25.028735513018084, 25.00372173320547, 24.978732952072974, 24.953769145099372, 24.928830286833463, 24.90391635274385, 24."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879027317548697, 24.854163156408593, 24.829323844688194, 24.804509357299377, 24.77971966977584, 24.75495475725826, 24.73021459515047, 24.70549915810568, 24.680808422054984, 24.656142362237727, 24.631500953917946, 24.606884172921824, 24.582291993607555, 24.55772439179137, 24.533181343730682, 24.508662824096437, 24.484168808240714, 24.4596992721371, 24.435254190709326, 24.410833540039526, 24.386437295876423, 24.36206543405181, 24.337717929706113, 24.313394758720587, 24.28909589676193, 24.264821319461316, 24.240571002713178, 24.216344922495566, 24.1921430541545, 24.16796537359756, 24.143811856994617, 24.119682479883718, 24.09557721794614, 24.071496047544166, 24.047438944765446, 24.023405885184033, 23.999396844578243, 23.97541179910773, 23.951450724956448, 23.927513598570854, 23.903600395048517, 23.879711091182738, 23.85584566319307, 23.83200408684559, 23.808186338109756, 23.78439239369477, 23.760622229677292, 23.73687582239617, 23.71315314755763, 23.689454182205104, 23.665778902629018, 23.642127284487387, 23.61849930489416, 23.594894939554848, 23.571314165391843, 23.54775695857583, 23.524223295658697, 23.500713153036433, 23.47722650760654, 23.453763335514047, 23.430323613464296, 23.406907318067656, 23.383514425777776, 23.360144913071803, 23.33679875663068, 23.31347593351511, 23.29017641997438, 23.2669001929378, 23.243647229178514, 23.220417505432803, 23.197210998818985, 23.17402768576199)\n"
     ]
    }
   ],
   "source": [
    "println(allRounds.unsafePerformSync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mjump\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jump[A](a: A)(implicit executionContext: scala.concurrent.ExecutionContext): Task[A] = {\n",
    "    import scalaz._\n",
    "    Task.async { handler: ((Throwable \\/ A) => Unit) =>\n",
    "      executionContext.execute {\n",
    "        new Runnable {\n",
    "          override def run(): Unit = handler(\\/-(a))\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgenIdx\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgenerate\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genIdx(v: INDArray): Int = Nd4j.getExecutioner().execAndReturn(new IMax(v)).getFinalResult()\n",
    "\n",
    "def generate(seed: Char, n: Int): Task[String] = ((0 until n).foldLeftM((seed.toString, initH)) {\n",
    "  (st: (String, INDArrayLayer), i: Int) =>\n",
    "    st match {\n",
    "      case (tot, hprev) => {\n",
    "        val x = oneOfK(tot.last)\n",
    "        charRNN(x, x, hprev) match {\n",
    "          case (_, prob, hnext) =>\n",
    "              prob.predict.flatMap { (probv: INDArray) =>\n",
    "                jump {\n",
    "                val nidx = genIdx(probv)\n",
    "                val nc = ixToChar(nidx)\n",
    "                (tot + nc.toString, hnext)\n",
    "              }\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "}).map { (st: (String, INDArrayLayer)) =>\n",
    "  st match {\n",
    "    case (r, _) => r\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres14\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"DeepLearning.scalaarning.rniee.rn\"\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('D', 32).unsafePerformSync"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
